{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a0b3841",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "In this lesson, you will learn how to create and select features for machine learning models. Feature engineering is a critical step that can significantly enhance model performance by providing the model with the most relevant information.\n",
    "\n",
    "## Learning Objectives\n",
    "- Define feature engineering and its importance in machine learning.\n",
    "- Create new features from existing data to improve model performance.\n",
    "- Select important features that contribute to the model's predictive power.\n",
    "- Understand dimensionality reduction techniques and their applications.\n",
    "- Explore practical examples of feature engineering in real-world scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7399f38",
   "metadata": {},
   "source": [
    "## Why This Matters\n",
    "\n",
    "Feature engineering is essential because it directly impacts the performance of machine learning models. By creating and selecting the right features, you can improve model accuracy, reduce overfitting, and enhance interpretability. This process allows you to leverage domain knowledge to extract meaningful insights from raw data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e88431",
   "metadata": {},
   "source": [
    "### Concept 1: Feature Creation\n",
    "\n",
    "Feature creation involves generating new features from existing data to provide additional insights for the model. This can include interaction features and polynomial features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab24b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of creating interaction features\n",
    "import pandas as pd\n",
    "\n",
    "# Sample dataset\n",
    "data = {'feature1': [1, 2, 3], 'feature2': [4, 5, 6]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Creating an interaction feature\n",
    "# Interaction feature is the product of feature1 and feature2\n",
    "\n",
    "df['interaction_feature'] = df['feature1'] * df['feature2']\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8691e6",
   "metadata": {},
   "source": [
    "#### Micro-Exercise 1\n",
    "\n",
    "Explain what feature engineering is and why it is important.\n",
    "\n",
    "```python\n",
    "# Feature engineering explanation\n",
    "# Feature engineering is the process of using domain knowledge to create features that make machine learning algorithms work.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b242469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Micro-Exercise 1 Starter Code\n",
    "# Let's define a function to explain feature engineering\n",
    "\n",
    "def explain_feature_engineering():\n",
    "    explanation = \"Feature engineering is the process of using domain knowledge to create features that make machine learning algorithms work.\"\n",
    "    return explanation\n",
    "\n",
    "print(explain_feature_engineering())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16831817",
   "metadata": {},
   "source": [
    "### Concept 2: Feature Selection\n",
    "\n",
    "Feature selection is the process of identifying and selecting a subset of relevant features for model training. This helps in reducing overfitting and improving model interpretability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ee73f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of feature selection using filter methods\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "# Load iris dataset\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Select the top 2 features based on ANOVA F-value\n",
    "selector = SelectKBest(score_func=f_classif, k=2)\n",
    "X_new = selector.fit_transform(X, y)\n",
    "print(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4826e7d",
   "metadata": {},
   "source": [
    "#### Micro-Exercise 2\n",
    "\n",
    "List and describe two techniques for feature selection.\n",
    "\n",
    "```python\n",
    "# Feature selection techniques\n",
    "# 1. Filter methods: Evaluate features based on statistical tests.\n",
    "# 2. Wrapper methods: Use a predictive model to evaluate feature subsets.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b5c3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Micro-Exercise 2 Starter Code\n",
    "# Let's define a function to list feature selection techniques\n",
    "\n",
    "def feature_selection_techniques():\n",
    "    techniques = {\n",
    "        'Filter methods': 'Evaluate features based on statistical tests.',\n",
    "        'Wrapper methods': 'Use a predictive model to evaluate feature subsets.'\n",
    "    }\n",
    "    return techniques\n",
    "\n",
    "print(feature_selection_techniques())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7823575",
   "metadata": {},
   "source": [
    "## Examples\n",
    "\n",
    "### Example 1: Creating Interaction Features for Marketing Analysis\n",
    "This example demonstrates how to create interaction features to analyze the effectiveness of a marketing campaign.\n",
    "\n",
    "```python\n",
    "# Code to create interaction features\n",
    "# df['interaction_feature'] = df['feature1'] * df['feature2']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6775ed",
   "metadata": {},
   "source": [
    "### Example 2: Using PCA for Dimensionality Reduction in Image Classification\n",
    "This example shows how to apply PCA to reduce the number of features in an image dataset while retaining essential information.\n",
    "\n",
    "```python\n",
    "# Code to apply PCA\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "X_reduced = pca.fit_transform(X)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f99ea2",
   "metadata": {},
   "source": [
    "## Micro-exercises\n",
    "\n",
    "### Exercise 1\n",
    "Explain what feature engineering is and why it is important.\n",
    "\n",
    "```python\n",
    "# Feature engineering explanation\n",
    "# Feature engineering is the process of using domain knowledge to create features that make machine learning algorithms work.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1594ec5",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "List and describe two techniques for feature selection.\n",
    "\n",
    "```python\n",
    "# Feature selection techniques\n",
    "# 1. Filter methods: Evaluate features based on statistical tests.\n",
    "# 2. Wrapper methods: Use a predictive model to evaluate feature subsets.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cd1a3d",
   "metadata": {},
   "source": [
    "## Main Exercise: Feature Engineering Project\n",
    "In this exercise, you will load a dataset, create new features, and select the most important features to improve model performance.\n",
    "\n",
    "```python\n",
    "# Load dataset\n",
    "import pandas as pd\n",
    "df = pd.read_csv('data.csv')\n",
    "\n",
    "# Create new features\n",
    "# Example of creating a new feature\n",
    "# df['new_feature'] = df['feature1'] * df['feature2']\n",
    "\n",
    "# Implement feature selection techniques\n",
    "# from sklearn.feature_selection import SelectKBest\n",
    "# selector = SelectKBest(k=2)\n",
    "# X_selected = selector.fit_transform(X, y)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633c9193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Exercise Starter Code\n",
    "# Let's implement a simple feature engineering process\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "# Load iris dataset\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "df = pd.DataFrame(X, columns=iris.feature_names)\n",
    "\n",
    "# Create a new feature\n",
    "# Example: Adding a new feature as the sum of two existing features\n",
    "\n",
    "df['sum_feature'] = df['sepal length (cm)'] + df['sepal width (cm)']\n",
    "\n",
    "# Feature selection\n",
    "selector = SelectKBest(score_func=f_classif, k=2)\n",
    "X_selected = selector.fit_transform(df, y)\n",
    "print(X_selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393ddb14",
   "metadata": {},
   "source": [
    "## Common Mistakes\n",
    "- Overfitting by adding too many features without validation.\n",
    "- Ignoring feature importance which can lead to unnecessary complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ade4a2",
   "metadata": {},
   "source": [
    "## Recap & Next Steps\n",
    "In this lesson, we covered the importance of feature engineering, techniques for creating and selecting features, and practical examples. Next, we will explore model training and evaluation in AWS SageMaker."
   ]
  }
 ],
 "metadata": {
  "doc_links_used": [],
  "estimated_minutes": 45,
  "tags": [
   "beginner",
   "python"
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
