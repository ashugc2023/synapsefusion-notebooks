{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0d65c74",
   "metadata": {},
   "source": [
    "# Evaluation Metrics\n",
    "\n",
    "In this lesson, you will learn about various evaluation metrics used to assess the performance of machine learning models. By the end of this lesson, you will be able to calculate and interpret these metrics to make informed decisions about model effectiveness.\n",
    "\n",
    "## Learning Objectives\n",
    "- Identify common evaluation metrics used in machine learning.\n",
    "- Understand the significance of each metric.\n",
    "- Choose appropriate metrics based on model type and business goals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03adc30b",
   "metadata": {},
   "source": [
    "## Why This Matters\n",
    "\n",
    "Evaluation metrics are crucial in machine learning as they provide insights into how well a model performs. Understanding these metrics helps in making informed decisions about model selection and improvement, ensuring that the chosen model aligns with business objectives and minimizes risks associated with incorrect predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7493b286",
   "metadata": {},
   "source": [
    "## Accuracy\n",
    "\n",
    "### Explanation\n",
    "Accuracy is the ratio of correctly predicted instances to the total instances in the dataset. It is a fundamental metric for evaluating classification models.\n",
    "\n",
    "### Why It Matters\n",
    "Accuracy provides a straightforward measure of how often the model is correct, making it a fundamental metric for classification tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e745dd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Calculate Accuracy\n",
    "# Assuming we have true positives, true negatives, false positives, and false negatives\n",
    "true_positives = 50\n",
    "true_negatives = 30\n",
    "false_positives = 10\n",
    "false_negatives = 5\n",
    "\n",
    "# Calculate total predictions\n",
    "total_predictions = true_positives + true_negatives + false_positives + false_negatives\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = (true_positives + true_negatives) / total_predictions\n",
    "print(f'Accuracy: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f33a44",
   "metadata": {},
   "source": [
    "## Micro-Exercise 1\n",
    "\n",
    "List at least three evaluation metrics used in machine learning.\n",
    "\n",
    "```python\n",
    "# Example metrics: Accuracy, Precision, Recall\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c95e0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Micro-Exercise 1 Starter Code\n",
    "# List of metrics\n",
    "metrics = ['Accuracy', 'Precision', 'Recall']\n",
    "print('Evaluation Metrics:', metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c8f443",
   "metadata": {},
   "source": [
    "## Precision and Recall\n",
    "\n",
    "### Explanation\n",
    "Precision is the ratio of true positive predictions to the total predicted positives, while recall is the ratio of true positives to the total actual positives. These metrics help assess the model's performance in scenarios where class distribution is imbalanced.\n",
    "\n",
    "### Why It Matters\n",
    "Precision and recall are crucial for understanding the trade-offs between false positives and false negatives, especially in imbalanced datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6eda279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Calculate Precision and Recall\n",
    "# Assuming we have true positives and false positives/negatives\n",
    "true_positives = 50\n",
    "false_positives = 10\n",
    "false_negatives = 5\n",
    "\n",
    "# Calculate precision and recall\n",
    "precision = true_positives / (true_positives + false_positives)\n",
    "recall = true_positives / (true_positives + false_negatives)\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a90e5d",
   "metadata": {},
   "source": [
    "## Micro-Exercise 2\n",
    "\n",
    "Explain why precision and recall are important in classification tasks.\n",
    "\n",
    "```python\n",
    "# Precision and recall help assess the model's performance in imbalanced datasets.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3921bd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Micro-Exercise 2 Starter Code\n",
    "# Explanation of importance\n",
    "importance = 'Precision and recall are crucial for evaluating model performance in imbalanced datasets.'\n",
    "print(importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45c9fc5",
   "metadata": {},
   "source": [
    "## F1 Score\n",
    "\n",
    "### Explanation\n",
    "The F1 Score combines precision and recall into a single metric, providing a balance that is particularly useful when dealing with uneven class distributions.\n",
    "\n",
    "### Why It Matters\n",
    "The F1 Score is useful because it considers both false positives and false negatives, making it a better measure than accuracy in cases of class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4620ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Calculate F1 Score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Assuming we have predictions and true labels\n",
    "true_labels = [1, 0, 1, 1, 0, 1, 0, 0, 1, 0]\n",
    "predictions = [1, 0, 1, 0, 0, 1, 0, 1, 1, 0]\n",
    "\n",
    "# Calculate F1 Score\n",
    "f1 = f1_score(true_labels, predictions)\n",
    "print(f'F1 Score: {f1:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7e273c",
   "metadata": {},
   "source": [
    "## Examples Section\n",
    "\n",
    "### Example 1: Accuracy Calculation\n",
    "Demonstrating how to calculate accuracy using a simple classification model.\n",
    "\n",
    "```python\n",
    "# Calculate accuracy\n",
    "accuracy = (true_positives + true_negatives) / total_predictions\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba7ddca",
   "metadata": {},
   "source": [
    "### Example 2: Precision and Recall in Fraud Detection\n",
    "Using precision and recall to evaluate a model designed to detect fraudulent transactions.\n",
    "\n",
    "```python\n",
    "# Calculate precision and recall\n",
    "precision = true_positives / (true_positives + false_positives)\n",
    "recall = true_positives / (true_positives + false_negatives)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1a9b61",
   "metadata": {},
   "source": [
    "## Micro-Exercises Section\n",
    "\n",
    "1. List at least three evaluation metrics used in machine learning.\n",
    "   ```python\n",
    "   # Example metrics: Accuracy, Precision, Recall\n",
    "   ```\n",
    "\n",
    "2. Explain why precision and recall are important in classification tasks.\n",
    "   ```python\n",
    "   # Precision and recall help assess the model's performance in imbalanced datasets.\n",
    "   ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77dbf045",
   "metadata": {},
   "source": [
    "## Main Exercise\n",
    "In this exercise, you will load a sample dataset, train a simple classification model, and calculate accuracy, precision, recall, and F1 score using the model's predictions. You will then interpret the results and discuss their implications.\n",
    "\n",
    "### Starter Code\n",
    "```python\n",
    "# Load dataset\n",
    "import pandas as pd\n",
    "dataset = pd.read_csv('sample_data.csv')\n",
    "\n",
    "# Train model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset.drop('target', axis=1), dataset['target'], test_size=0.2)\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "precision = precision_score(y_test, predictions)\n",
    "recall = recall_score(y_test, predictions)\n",
    "f1 = f1_score(y_test, predictions)\n",
    "\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1 Score: {f1:.2f}')\n",
    "```\n",
    "### Expected Outcomes\n",
    "- A report detailing the calculated metrics and their significance.\n",
    "- Understanding of how to interpret the results in the context of model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22d8a6f",
   "metadata": {},
   "source": [
    "## Common Mistakes\n",
    "- Focusing only on accuracy without considering other metrics.\n",
    "- Ignoring the implications of model bias and variance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2dfd7aa",
   "metadata": {},
   "source": [
    "## Recap\n",
    "In this lesson, you learned about key evaluation metrics such as accuracy, precision, recall, and the F1 score. Understanding these metrics is essential for assessing model performance effectively. In the next lesson, we will explore model tuning and optimization techniques to improve these metrics further."
   ]
  }
 ],
 "metadata": {
  "doc_links_used": [],
  "estimated_minutes": 45,
  "tags": [
   "beginner",
   "python"
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
