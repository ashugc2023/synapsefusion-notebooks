{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9641762",
   "metadata": {},
   "source": [
    "# Using Built-in Algorithms\n",
    "\n",
    "In this lesson, we will explore the built-in algorithms available in AWS SageMaker for model training. By the end of this lesson, you will be able to identify different algorithms, understand their use cases, and effectively train a model using a built-in algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b447170",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "- Identify built-in algorithms available in SageMaker.\n",
    "- Understand the use cases for different algorithms.\n",
    "- Train a model using a built-in algorithm effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab564e1",
   "metadata": {},
   "source": [
    "## Why This Matters\n",
    "\n",
    "Built-in algorithms simplify the model training process, allowing users to focus on data and results rather than implementation details. By leveraging these algorithms, you can quickly build and deploy machine learning models without needing extensive programming knowledge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c40c97b",
   "metadata": {},
   "source": [
    "### Concept 1: Built-in Algorithms\n",
    "\n",
    "Built-in algorithms are pre-implemented algorithms provided by SageMaker that simplify the model training process. They allow users to leverage powerful machine learning techniques without needing to implement them from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c225280c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: List of built-in algorithms in SageMaker\n",
    "# This code snippet lists some of the built-in algorithms available in SageMaker.\n",
    "\n",
    "built_in_algorithms = [\n",
    "    'XGBoost',\n",
    "    'Linear Learner',\n",
    "    'Factorization Machines',\n",
    "    'K-Means',\n",
    "    'Object Detection'\n",
    "]\n",
    "\n",
    "print('Built-in Algorithms in SageMaker:')\n",
    "for algo in built_in_algorithms:\n",
    "    print('-', algo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fbbe4c",
   "metadata": {},
   "source": [
    "### Micro-Exercise 1\n",
    "\n",
    "Identify at least three built-in algorithms available in SageMaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5216ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Micro-exercise starter code\n",
    "# List of built-in algorithms\n",
    "# Fill in the list with your answers\n",
    "my_built_in_algorithms = [\n",
    "    'Algorithm 1',\n",
    "    'Algorithm 2',\n",
    "    'Algorithm 3'\n",
    "]\n",
    "\n",
    "print('Your built-in algorithms:')\n",
    "for algo in my_built_in_algorithms:\n",
    "    print('-', algo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0598cbea",
   "metadata": {},
   "source": [
    "### Concept 2: Algorithm Selection\n",
    "\n",
    "Algorithm selection involves choosing the most suitable algorithm for a given problem based on the nature of the data and the desired outcome. Different algorithms have different strengths and weaknesses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174943ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Factors influencing algorithm choice\n",
    "# This code snippet illustrates how to choose an algorithm based on the problem type.\n",
    "\n",
    "problem_type = 'classification'\n",
    "\n",
    "if problem_type == 'classification':\n",
    "    recommended_algorithm = 'XGBoost'\n",
    "elif problem_type == 'regression':\n",
    "    recommended_algorithm = 'Linear Learner'\n",
    "else:\n",
    "    recommended_algorithm = 'K-Means'\n",
    "\n",
    "print(f'Recommended algorithm for {problem_type}: {recommended_algorithm}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbe827a",
   "metadata": {},
   "source": [
    "### Micro-Exercise 2\n",
    "\n",
    "Match the following algorithms to their appropriate use cases:\n",
    "1. XGBoost\n",
    "2. Linear Learner\n",
    "3. K-Means\n",
    "\n",
    "- A. Predicting housing prices\n",
    "- B. Customer segmentation\n",
    "- C. Credit scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75ed3e6",
   "metadata": {},
   "source": [
    "## Examples Section\n",
    "\n",
    "### Example 1: Using XGBoost for Classification Tasks\n",
    "This example demonstrates how to use the XGBoost algorithm for a classification task in finance, such as credit scoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c049acb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example code for training XGBoost model\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.estimator import Estimator\n",
    "\n",
    "# Define the role and session\n",
    "role = get_execution_role()\n",
    "session = sagemaker.Session()\n",
    "\n",
    "# Define the XGBoost estimator\n",
    "xgboost_estimator = Estimator(\n",
    "    image_uri=sagemaker.image_uris.retrieve('xgboost', session.boto_region_name),\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.large',\n",
    "    output_path='s3://your-bucket/output',\n",
    "    sagemaker_session=session\n",
    ")\n",
    "\n",
    "# Set hyperparameters\n",
    "xgboost_estimator.set_hyperparameters(\n",
    "    objective='binary:logistic',\n",
    "    num_round=100\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "xgboost_estimator.fit({'train': 's3://your-bucket/train-data'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91de8a1b",
   "metadata": {},
   "source": [
    "### Example 2: Training a Linear Regression Model\n",
    "This example shows how to train a linear regression model for predicting housing prices using SageMaker's built-in algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1bb847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example code for training Linear Regression model\n",
    "from sagemaker.linear_learner import LinearLearner\n",
    "\n",
    "# Define the Linear Learner estimator\n",
    "linear_estimator = LinearLearner(\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.large',\n",
    "    predictor_type='regressor',\n",
    "    output_path='s3://your-bucket/output',\n",
    "    sagemaker_session=session\n",
    ")\n",
    "\n",
    "# Set hyperparameters\n",
    "linear_estimator.set_hyperparameters(\n",
    "    feature_dim=10,\n",
    "    predictor_type='regressor',\n",
    "    mini_batch_size=32\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "linear_estimator.fit({'train': 's3://your-bucket/train-data'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf322f43",
   "metadata": {},
   "source": [
    "## Main Exercise\n",
    "### Training a Model with XGBoost\n",
    "In this exercise, you will load a dataset into SageMaker, select the XGBoost algorithm, configure the training job parameters, and evaluate the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4053de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset and train XGBoost model\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load your dataset\n",
    "data = pd.read_csv('s3://your-bucket/dataset.csv')\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "train_data, test_data = train_test_split(data, test_size=0.2)\n",
    "\n",
    "# Save the datasets to S3\n",
    "train_data.to_csv('s3://your-bucket/train-data', index=False)\n",
    "test_data.to_csv('s3://your-bucket/test-data', index=False)\n",
    "\n",
    "# Now you can use the previous XGBoost code to train the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce51b43d",
   "metadata": {},
   "source": [
    "## Common Mistakes\n",
    "- Choosing the wrong algorithm for the problem at hand.\n",
    "- Neglecting to tune hyperparameters after selecting an algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82931648",
   "metadata": {},
   "source": [
    "## Recap & Next Steps\n",
    "In this lesson, we learned about the built-in algorithms in SageMaker and how to select the appropriate algorithm for different use cases. We also practiced training models using XGBoost and Linear Learner. In the next lesson, we will explore hyperparameter tuning to optimize model performance."
   ]
  }
 ],
 "metadata": {
  "doc_links_used": [],
  "estimated_minutes": 45,
  "tags": [
   "beginner",
   "python",
   "aws",
   "sagemaker"
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
