{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0a7d2fa",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning\n",
    "\n",
    "In this lesson, we will explore the concept of hyperparameter tuning, its significance in improving model performance, and how to apply various tuning methods in AWS SageMaker."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2b4483",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "- Define hyperparameters and their role in model training.\n",
    "- Understand different methods for hyperparameter tuning.\n",
    "- Apply hyperparameter tuning techniques in SageMaker."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3930a012",
   "metadata": {},
   "source": [
    "## Why This Matters\n",
    "\n",
    "Hyperparameters are crucial in determining the performance of machine learning models. Proper tuning can lead to improved accuracy and generalization, making it essential for building effective models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1bc391",
   "metadata": {},
   "source": [
    "## Concept: Hyperparameters\n",
    "### Explanation\n",
    "Hyperparameters are configuration settings used to control the training process of machine learning models. They are not learned from the data but are set prior to the training phase.\n",
    "\n",
    "### Why It Matters\n",
    "Hyperparameters significantly influence the learning process and performance of machine learning models. Proper tuning can lead to better accuracy and generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4732d176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Defining Hyperparameters\n",
    "# Here we define some common hyperparameters for an XGBoost model.\n",
    "import xgboost as xgb\n",
    "\n",
    "# Define hyperparameters\n",
    "params = {\n",
    "    'learning_rate': 0.1,  # Step size shrinkage\n",
    "    'max_depth': 3,        # Maximum depth of a tree\n",
    "    'n_estimators': 100,   # Number of trees\n",
    "    'objective': 'reg:squarederror'  # Learning task\n",
    "}\n",
    "\n",
    "print('Defined hyperparameters:', params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51449610",
   "metadata": {},
   "source": [
    "### Micro-Exercise\n",
    "Explain what hyperparameters are and give examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcbf477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Micro-exercise starter code\n",
    "# Definition and examples\n",
    "# Hyperparameters are settings that control the training process.\n",
    "# Examples include learning rate, max depth, and number of estimators."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61eaf372",
   "metadata": {},
   "source": [
    "## Concept: Tuning Methods\n",
    "### Explanation\n",
    "Tuning methods are strategies used to find the optimal hyperparameters for a model. These methods systematically explore different combinations of hyperparameters to improve model performance.\n",
    "\n",
    "### Why It Matters\n",
    "Different tuning methods can lead to varying levels of model performance, making it essential to choose the right approach to achieve the best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe9c7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Comparing Tuning Methods\n",
    "# This example demonstrates a simple grid search for hyperparameter tuning.\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Define model\n",
    "model = RandomForestRegressor()\n",
    "\n",
    "# Define hyperparameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20]\n",
    "}\n",
    "\n",
    "# Set up grid search\n",
    "grid_search = GridSearchCV(model, param_grid, cv=3)\n",
    "\n",
    "print('Grid search set up with parameters:', param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d868597b",
   "metadata": {},
   "source": [
    "### Micro-Exercise\n",
    "List and describe two methods for hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6bd7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Micro-exercise starter code\n",
    "# Tuning methods\n",
    "# 1. Grid Search: Exhaustively searches through a specified subset of hyperparameters.\n",
    "# 2. Random Search: Samples a fixed number of hyperparameter settings from specified distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4230b1b",
   "metadata": {},
   "source": [
    "## Examples Section\n",
    "### Example 1: Hyperparameter Impact on Model Performance\n",
    "This example demonstrates how changing the learning rate affects the convergence of a model during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8956342a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example code to visualize learning rate impact\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Simulated training loss for different learning rates\n",
    "learning_rates = [0.01, 0.1, 0.2]\n",
    "losses = {lr: np.random.rand(100) + lr for lr in learning_rates}\n",
    "\n",
    "# Plotting\n",
    "for lr, loss in losses.items():\n",
    "    plt.plot(loss, label=f'Learning Rate: {lr}')\n",
    "plt.title('Impact of Learning Rate on Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9144fc4",
   "metadata": {},
   "source": [
    "### Example 2: Comparing Tuning Methods\n",
    "This example compares the performance of a model tuned using grid search versus random search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8df67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example code to compare tuning methods\n",
    "# Assuming previous imports and model definitions\n",
    "# Random search setup\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(model, param_grid, n_iter=10, cv=3)\n",
    "\n",
    "print('Random search set up with parameters:', param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ef8b71",
   "metadata": {},
   "source": [
    "## Main Exercise: Tuning Hyperparameters for XGBoost\n",
    "In this exercise, you will set up a hyperparameter tuning job in SageMaker for an XGBoost model. You will define the hyperparameter ranges to explore, run the tuning job, and analyze the results to find the best performing model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751e7e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and define hyperparameter ranges for XGBoost\n",
    "import boto3\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.estimator import Estimator\n",
    "\n",
    "# Define role and session\n",
    "role = get_execution_role()\n",
    "session = boto3.Session()\n",
    "\n",
    "# Define XGBoost estimator\n",
    "xgb = Estimator(image_uri='your-xgboost-image-uri',\n",
    "                role=role,\n",
    "                instance_count=1,\n",
    "                instance_type='ml.m5.large',\n",
    "                output_path='s3://your-bucket/output')\n",
    "\n",
    "# Define hyperparameter ranges\n",
    "xgb.set_hyperparameters(\n",
    "    objective='reg:squarederror',\n",
    "    num_round=100,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=5\n",
    ")\n",
    "\n",
    "print('XGBoost estimator set up with hyperparameters.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36129773",
   "metadata": {},
   "source": [
    "## Common Mistakes\n",
    "- Not tuning hyperparameters at all.\n",
    "- Overfitting the model during the tuning process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63eccc2e",
   "metadata": {},
   "source": [
    "## Recap & Next Steps\n",
    "In this lesson, we covered the importance of hyperparameter tuning, explored different tuning methods, and practiced setting up a tuning job in SageMaker. Next, we will delve into model evaluation and selection."
   ]
  }
 ],
 "metadata": {
  "doc_links_used": [],
  "estimated_minutes": 45,
  "tags": [
   "beginner",
   "python",
   "aws",
   "sagemaker",
   "machine learning"
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
