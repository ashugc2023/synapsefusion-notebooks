{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e81f4e6",
   "metadata": {},
   "source": [
    "# Deploying and Evaluating the Model\n",
    "\n",
    "In this lesson, you will learn how to deploy a trained machine learning model using AWS SageMaker and evaluate its performance in a production environment. By the end of this lesson, you will be able to:\n",
    "\n",
    "- Deploy the model using SageMaker\n",
    "- Evaluate the deployed model\n",
    "- Optimize based on feedback\n",
    "- Understand monitoring strategies\n",
    "- Identify performance metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab2c150",
   "metadata": {},
   "source": [
    "## Why This Matters\n",
    "\n",
    "Deploying a machine learning model is crucial as it makes the model accessible for real-world applications, allowing users to benefit from its predictions. Evaluating the model's performance post-deployment ensures that it meets user expectations and continues to perform effectively over time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6148457",
   "metadata": {},
   "source": [
    "## Model Deployment\n",
    "\n",
    "Model deployment is the process of making a trained machine learning model available for use in a production environment. This involves setting up the necessary infrastructure to serve predictions and ensuring that the model can handle incoming requests efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f286fc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Deploying a model to SageMaker\n",
    "import boto3\n",
    "\n",
    "# Create a SageMaker client\n",
    "sagemaker_client = boto3.client('sagemaker')\n",
    "\n",
    "# Define model parameters\n",
    "model_name = 'my-trained-model'\n",
    "endpoint_config_name = 'my-endpoint-config'\n",
    "endpoint_name = 'my-endpoint'\n",
    "\n",
    "# Create an endpoint configuration\n",
    "sagemaker_client.create_endpoint_config(\n",
    "    EndpointConfigName=endpoint_config_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            'VariantName': 'AllTraffic',\n",
    "            'ModelName': model_name,\n",
    "            'InitialInstanceCount': 1,\n",
    "            'InstanceType': 'ml.m5.large'\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create an endpoint\n",
    "sagemaker_client.create_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    EndpointConfigName=endpoint_config_name\n",
    ")\n",
    "\n",
    "print('Model deployed to endpoint:', endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa7f821",
   "metadata": {},
   "source": [
    "### Micro-Exercise 1\n",
    "\n",
    "List the steps involved in deploying a machine learning model.\n",
    "\n",
    "```python\n",
    "# List the steps involved in deploying a machine learning model.\n",
    "# Hint: Consider the infrastructure and configuration needed.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb5353b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Micro-Exercise 1: Deployment Steps\n",
    "# Step 1: Prepare the model artifacts.\n",
    "# Step 2: Create a SageMaker model.\n",
    "# Step 3: Create an endpoint configuration.\n",
    "# Step 4: Create an endpoint.\n",
    "# Step 5: Test the endpoint with sample data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e627c2",
   "metadata": {},
   "source": [
    "## Performance Evaluation\n",
    "\n",
    "Performance evaluation involves assessing the effectiveness of the deployed model based on various metrics and user feedback. This ensures that the model continues to meet the expectations of its users and performs well over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a711167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Evaluating model performance\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# Define the endpoint URL\n",
    "endpoint_url = 'https://my-endpoint.amazonaws.com/invocations'\n",
    "\n",
    "# Sample input data\n",
    "input_data = {'instances': [{'data': [1.0, 2.0, 3.0]}]}\n",
    "\n",
    "# Make a prediction request\n",
    "response = requests.post(endpoint_url, json=input_data)\n",
    "\n",
    "# Get the prediction result\n",
    "prediction = response.json()\n",
    "print('Model prediction:', prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40cad59b",
   "metadata": {},
   "source": [
    "### Micro-Exercise 2\n",
    "\n",
    "Describe how to evaluate the performance of a deployed model.\n",
    "\n",
    "```python\n",
    "# Describe how to evaluate the performance of a deployed model.\n",
    "# Hint: Think about metrics and user feedback.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed703eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Micro-Exercise 2: Post-Deployment Evaluation\n",
    "# To evaluate a deployed model, consider the following:\n",
    "# 1. Collect user feedback on predictions.\n",
    "# 2. Analyze performance metrics such as accuracy and latency.\n",
    "# 3. Monitor the model's performance over time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e918b69d",
   "metadata": {},
   "source": [
    "## Examples\n",
    "\n",
    "### Example 1: Deploying a Customer Segmentation Model\n",
    "This example demonstrates how to deploy a customer segmentation model using AWS SageMaker and evaluate its performance based on user feedback.\n",
    "\n",
    "```python\n",
    "# Code to deploy the model and evaluate performance metrics.\n",
    "# (Refer to previous code snippets for deployment and evaluation)\n",
    "```\n",
    "\n",
    "### Example 2: Scaling a Deployed Model\n",
    "This example illustrates how to scale a deployed model to handle increased traffic and ensure consistent performance.\n",
    "\n",
    "```python\n",
    "# Code to configure auto-scaling for the deployed model.\n",
    "import boto3\n",
    "\n",
    "# Create an application auto-scaling client\n",
    "client = boto3.client('application-autoscaling')\n",
    "\n",
    "# Define scaling policy\n",
    "client.put_scaling_policy(\n",
    "    PolicyName='my-scaling-policy',\n",
    "    ServiceNamespace='sagemaker',\n",
    "    ResourceId='endpoint/my-endpoint',\n",
    "    ScalableDimension='sagemaker:variant:DesiredInstanceCount',\n",
    "    PolicyType='TargetTrackingScaling',\n",
    "    TargetTrackingScalingPolicyConfiguration={\n",
    "        'TargetValue': 75.0,\n",
    "        'PredefinedMetricSpecification': {\n",
    "            'PredefinedMetricType': 'SageMakerVariantInvocationsPerInstance'\n",
    "        },\n",
    "        'ScaleInCooldown': 60,\n",
    "        'ScaleOutCooldown': 60\n",
    "    }\n",
    ")\n",
    "print('Auto-scaling policy configured.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30f7999",
   "metadata": {},
   "source": [
    "## Main Exercise\n",
    "In this exercise, you will deploy a trained machine learning model to a SageMaker endpoint, test it with sample inputs, and collect performance metrics for evaluation.\n",
    "\n",
    "### Starter Code\n",
    "```python\n",
    "# Code to deploy the model and collect metrics.\n",
    "# (Refer to previous code snippets for deployment and evaluation)\n",
    "```\n",
    "\n",
    "### Expected Outcomes\n",
    "- A successfully deployed model on SageMaker.\n",
    "- Collected performance metrics for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fbe575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Exercise: Deploying and Evaluating the Model\n",
    "# Import necessary libraries\n",
    "import boto3\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# Function to deploy the model\n",
    "def deploy_model(model_name, endpoint_config_name, endpoint_name):\n",
    "    sagemaker_client = boto3.client('sagemaker')\n",
    "    # Create an endpoint configuration\n",
    "    sagemaker_client.create_endpoint_config(\n",
    "        EndpointConfigName=endpoint_config_name,\n",
    "        ProductionVariants=[\n",
    "            {\n",
    "                'VariantName': 'AllTraffic',\n",
    "                'ModelName': model_name,\n",
    "                'InitialInstanceCount': 1,\n",
    "                'InstanceType': 'ml.m5.large'\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    # Create an endpoint\n",
    "    sagemaker_client.create_endpoint(\n",
    "        EndpointName=endpoint_name,\n",
    "        EndpointConfigName=endpoint_config_name\n",
    "    )\n",
    "    print('Model deployed to endpoint:', endpoint_name)\n",
    "\n",
    "# Call the function to deploy the model\n",
    "deploy_model('my-trained-model', 'my-endpoint-config', 'my-endpoint')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8606f1f0",
   "metadata": {},
   "source": [
    "## Common Mistakes\n",
    "- Not monitoring the deployed model.\n",
    "- Ignoring user feedback."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ba3e32",
   "metadata": {},
   "source": [
    "## Recap\n",
    "In this lesson, you learned about deploying and evaluating machine learning models using AWS SageMaker. You explored deployment strategies, performance evaluation metrics, and optimization based on user feedback. In the next lesson, we will dive deeper into advanced model optimization techniques."
   ]
  }
 ],
 "metadata": {
  "doc_links_used": [],
  "estimated_minutes": 90,
  "tags": [
   "beginner",
   "aws",
   "sagemaker",
   "machine learning"
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
